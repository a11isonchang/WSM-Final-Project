ollama:
  host: "http://ollama-gateway:11434"
  model: "granite4:3b"

retrieval:
  chunk_size: 1000
  chunk_overlap: 200
  top_k: 3
  debug: false
  
  # Hybrid Retrieval Weights (a*TF-IDF + b*BM25 + c*JM = 1)
  weights:
    tfidf: 0  # a
    bm25: 1   # b
    jm: 0     # c

  # Pseudo-Relevance Feedback (PRF)
  prf_top_k: 0
  prf_term_count: 5

  # HyDE (Hypothetical Document Embeddings)
  hyde:
    enabled: false

  # Multi-Query (Generate variations + RRF Fusion)
  multi_query:
    enabled: false
    num_versions: 3

  # Model Hyperparameters
  bm25:
    k1: 1.5
    b: 0.75
  
  jm:
    lambda: 0.5

  # Dense re-ranking configuration (runs after lexical stage)
  dense:
    enabled: false
    type: "ollama"
    # Language-specific models
    model_en: "embeddinggemma:300m"
    model_zh: "qwen3-embedding:0.6b"
    # Fallback model (optional, used if language not specified)
    model: "embeddinggemma:300m"
    
    normalize: true
    batch_size: 32
    query_prefix: "search_query: "
    passage_prefix: "search_document: "

  candidate_multiplier: 20.0
