ollama:
  host: "http://ollama-gateway:11434"
  model: "granite4:3b"

retrieval:
  chunk_size: 400
  chunk_overlap: 150
  top_k: 6
  debug: false
  
  # Hybrid Retrieval Weights (a*TF-IDF + b*BM25 + c*JM = 1)
  weights:
    tfidf: 0.4  # a
    bm25: 0.4   # b
    jm: 0.2     # c

  # Pseudo-Relevance Feedback (PRF)
  prf_top_k: 3
  prf_term_count: 5

  # Model Hyperparameters
  bm25:
    k1: 1.5
    b: 0.75
  
  jm:
    lambda: 0.1

  # Dense re-ranking configuration (runs after lexical stage)
  dense:
    enabled: true
    type: "ollama"
    # Language-specific models
    model_en: "embeddinggemma:300m"
    model_zh: "qwen3-embedding:0.6b"
    # Fallback model (optional, used if language not specified)
    model: "embeddinggemma:300m"
    
    normalize: true
    batch_size: 32
    query_prefix: "search_query: "
    passage_prefix: "search_document: "

  candidate_multiplier: 20.0
