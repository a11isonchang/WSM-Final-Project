{
  "predictions_en_eval.jsonl": {
    "Sentences_Precision": 0.043606742930032354,
    "Sentences_Recall": 0.4444962598726103,
    "Words_Precision": 0.17863523856545907,
    "Words_Recall": 0.7500584171110539,
    "ROUGELScore": 0.24341328923932826,
    "completeness": 0.39479166666666665,
    "hallucination": 0.4302083333333333,
    "irrelevance": 0.175,
    "Words_F1": 0.2885491108067495,
    "Sentences_F1": 0.07942190081327166,
    "factual_score": -0.03541666666666665,
    "Generation_Total_Score": 0.1039983112863308,
    "Retrieval_Total_Score": 0.18398550581001058
  },
  "score_zh.jsonl": {
    "Sentences_Precision": 0.0870706479871903,
    "Sentences_Recall": 0.5132014606513722,
    "Words_Precision": 0.1751706499596003,
    "Words_Recall": 0.7250744934218164,
    "ROUGELScore": 0.41546862483265806,
    "completeness": 0.6481481481481481,
    "hallucination": 0.12962962962962962,
    "irrelevance": 0.2222222222222222,
    "Words_F1": 0.2821715200923112,
    "Sentences_F1": 0.14888175906834694,
    "factual_score": 0.5185185185185185,
    "Generation_Total_Score": 0.4669935716755883,
    "Retrieval_Total_Score": 0.21552663958032908
  },
  "score_test_zh.jsonl": {
    "Sentences_Precision": 0.024904570884005366,
    "Sentences_Recall": 0.4780882106262677,
    "Words_Precision": 0.09353080613706477,
    "Words_Recall": 0.7407727190454992,
    "ROUGELScore": 0.16499008526602527,
    "completeness": 0.3904761904761905,
    "hallucination": 0.08571428571428572,
    "irrelevance": 0.5238095238095237,
    "Words_F1": 0.1660907990566379,
    "Sentences_F1": 0.04734295269446523,
    "factual_score": 0.3047619047619048,
    "Generation_Total_Score": 0.23487599501396503,
    "Retrieval_Total_Score": 0.10671687587555156
  },
  "score_en.jsonl": {
    "Sentences_Precision": 0.0875364651798721,
    "Sentences_Recall": 0.39192954296480054,
    "Words_Precision": 0.19761278806219887,
    "Words_Recall": 0.5890264428093017,
    "ROUGELScore": 0.386227310541318,
    "completeness": 0.4683333333333334,
    "hallucination": 0.03333333333333333,
    "irrelevance": 0.49833333333333335,
    "Words_F1": 0.2959403829299216,
    "Sentences_F1": 0.14310973544697841,
    "factual_score": 0.43500000000000005,
    "Generation_Total_Score": 0.410613655270659,
    "Retrieval_Total_Score": 0.21952505918845
  },
  "predictions_zh_eval.jsonl": {
    "Sentences_Precision": 0.05831285882614827,
    "Sentences_Recall": 0.80631709284677,
    "Words_Precision": 0.15608068403432054,
    "Words_Recall": 0.8458646616541353,
    "ROUGELScore": 0.2517198044180765,
    "completeness": 0.4857142857142857,
    "hallucination": 0.18095238095238095,
    "irrelevance": 0.3333333333333333,
    "Words_F1": 0.2635336060186415,
    "Sentences_F1": 0.10876018049874525,
    "factual_score": 0.3047619047619048,
    "Generation_Total_Score": 0.27824085458999065,
    "Retrieval_Total_Score": 0.18614689325869338
  }
}