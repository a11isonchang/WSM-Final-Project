{
  "predictions_en_eval.jsonl": {
    "Sentences_Precision": 0.043606742930032354,
    "Sentences_Recall": 0.4444962598726103,
    "Words_Precision": 0.17863523856545907,
    "Words_Recall": 0.7500584171110539,
    "ROUGELScore": 0.24341328923932826,
    "completeness": 0.39479166666666665,
    "hallucination": 0.4302083333333333,
    "irrelevance": 0.175,
    "Words_F1": 0.2885491108067495,
    "Sentences_F1": 0.07942190081327166,
    "factual_score": -0.03541666666666665,
    "Generation_Total_Score": 0.1039983112863308,
    "Retrieval_Total_Score": 0.18398550581001058
  },
  "score_zh.jsonl": {
    "Sentences_Precision": 0.06943138859375717,
    "Sentences_Recall": 0.49825839700716024,
    "Words_Precision": 0.17729698462426421,
    "Words_Recall": 0.6949373932961878,
    "ROUGELScore": 0.44029702526224007,
    "completeness": 0.6190476190476192,
    "hallucination": 0.09523809523809523,
    "irrelevance": 0.2857142857142857,
    "Words_F1": 0.2825165057763804,
    "Sentences_F1": 0.12187914336378987,
    "factual_score": 0.523809523809524,
    "Generation_Total_Score": 0.482053274535882,
    "Retrieval_Total_Score": 0.20219782457008512
  },
  "score_test_zh.jsonl": {
    "Sentences_Precision": 0.024904570884005366,
    "Sentences_Recall": 0.4780882106262677,
    "Words_Precision": 0.09353080613706477,
    "Words_Recall": 0.7407727190454992,
    "ROUGELScore": 0.16499008526602527,
    "completeness": 0.3904761904761905,
    "hallucination": 0.08571428571428572,
    "irrelevance": 0.5238095238095237,
    "Words_F1": 0.1660907990566379,
    "Sentences_F1": 0.04734295269446523,
    "factual_score": 0.3047619047619048,
    "Generation_Total_Score": 0.23487599501396503,
    "Retrieval_Total_Score": 0.10671687587555156
  },
  "score_en.jsonl": {
    "Sentences_Precision": 0.08766651783067304,
    "Sentences_Recall": 0.3626001432963458,
    "Words_Precision": 0.20161149144144397,
    "Words_Recall": 0.6198495505335173,
    "ROUGELScore": 0.23583094263431906,
    "completeness": 0.35,
    "hallucination": 0.0625,
    "irrelevance": 0.5875,
    "Words_F1": 0.3042598150532384,
    "Sentences_F1": 0.1411958498021084,
    "factual_score": 0.2875,
    "Generation_Total_Score": 0.2616654713171595,
    "Retrieval_Total_Score": 0.2227278324276734
  },
  "predictions_zh_eval.jsonl": {
    "Sentences_Precision": 0.05831285882614827,
    "Sentences_Recall": 0.80631709284677,
    "Words_Precision": 0.15608068403432054,
    "Words_Recall": 0.8458646616541353,
    "ROUGELScore": 0.2517198044180765,
    "completeness": 0.4857142857142857,
    "hallucination": 0.18095238095238095,
    "irrelevance": 0.3333333333333333,
    "Words_F1": 0.2635336060186415,
    "Sentences_F1": 0.10876018049874525,
    "factual_score": 0.3047619047619048,
    "Generation_Total_Score": 0.27824085458999065,
    "Retrieval_Total_Score": 0.18614689325869338
  }
}